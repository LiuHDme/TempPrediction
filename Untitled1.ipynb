{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.linear_model import SGDRegressor, LinearRegression, Ridge\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "sub = pd.DataFrame(test_df['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[train_df['temperature'].notnull()]\n",
    "# train_df = train_df.fillna(method='bfill')\n",
    "# test_df = test_df.fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns = ['time','year','month','day','hour','min','sec','outdoorTemp','outdoorHum','outdoorAtmo','indoorHum','indoorAtmo', 'temperature']\n",
    "test_df.columns = ['time','year','month','day','hour','min','sec','outdoorTemp','outdoorHum','outdoorAtmo','indoorHum','indoorAtmo']\n",
    "tmp = train_df[['year', 'month', 'day', 'hour', 'min']].copy()\n",
    "tmp.columns = ['year', 'month', 'day', 'hour', 'minute']\n",
    "train_df['date'] = pd.to_datetime(tmp[['year', 'month', 'day', 'hour', 'minute']])\n",
    "tmp = test_df[['year', 'month', 'day', 'hour', 'min']].copy()\n",
    "tmp.columns = ['year', 'month', 'day', 'hour', 'minute']\n",
    "test_df['date'] = pd.to_datetime(tmp[['year', 'month', 'day', 'hour', 'minute']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:07<00:00,  1.27s/it]\n",
      "100%|██████████| 5/5 [00:00<00:00, 35.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "def fill_na(row, col):\n",
    "    if pd.isna(row[col]):\n",
    "        # 先看看前一分钟有没有\n",
    "        time = row.date - pd.Timedelta('1 minute')\n",
    "        pre = train_df.loc[train_df.date == time]\n",
    "        if len(pre) != 0 and pd.notna(pre[col].values[0]):\n",
    "            return pre[col].values[0]\n",
    "        else:\n",
    "            # 再看昨天有没有\n",
    "            time = row.date - pd.Timedelta('1 day')\n",
    "            pre = train_df.loc[train_df.date == time]\n",
    "            if len(pre) != 0 and pd.notna(pre[col].values[0]):\n",
    "                return pre[col].values[0]\n",
    "            else:\n",
    "                # 再看看前天有没有\n",
    "                time = row.date - pd.Timedelta('2 day')\n",
    "                pre = train_df.loc[train_df.date == time]\n",
    "                if len(pre) != 0 and pd.notna(pre[col].values[0]):\n",
    "                    return pre[col].values[0]\n",
    "                else:\n",
    "                    # 否则直接找上一个非空值\n",
    "                    pre = train_df.loc[(train_df.date < row.date) & (pd.notna(train[col]))].iloc[-1][col]\n",
    "                    return pre[col].values[0]\n",
    "            \n",
    "    return row[col]\n",
    "\n",
    "train_df.drop_duplicates(['month', 'day', 'hour', 'min'], inplace=True)\n",
    "\n",
    "for feat in tqdm(['outdoorTemp','outdoorHum','outdoorAtmo','indoorHum','indoorAtmo', 'temperature']):\n",
    "    train_df[feat] = train_df.apply(fill_na, axis=1, args=(feat,))\n",
    "\n",
    "# test\n",
    "def avg_pre_next(row, col):\n",
    "    if pd.isna(row[col]):\n",
    "        pre_val = test_df.loc[test_df.date < row.date].iloc[-1][col]\n",
    "        next_val = test_df.loc[test_df.date > row.date].iloc[0][col]\n",
    "        return (pre_val + next_val) / 2\n",
    "    return row[col]\n",
    "\n",
    "for feat in tqdm(['outdoorTemp','outdoorHum','outdoorAtmo','indoorHum','indoorAtmo']):\n",
    "    test_df[feat] = test_df.apply(avg_pre_next, axis=1, args=(feat,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.concat([train_df, test_df], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 15.70it/s]\n"
     ]
    }
   ],
   "source": [
    "# 基本聚合特征\n",
    "group_feats = []\n",
    "for f in tqdm(['outdoorTemp','outdoorHum','outdoorAtmo','indoorHum','indoorAtmo']):\n",
    "    data_df['MDH_{}_medi'.format(f)] = data_df.groupby(['month','day','hour'])[f].transform('median')\n",
    "    data_df['MDH_{}_mean'.format(f)] = data_df.groupby(['month','day','hour'])[f].transform('mean')\n",
    "    data_df['MDH_{}_max'.format(f)] = data_df.groupby(['month','day','hour'])[f].transform('max')\n",
    "    data_df['MDH_{}_min'.format(f)] = data_df.groupby(['month','day','hour'])[f].transform('min')\n",
    "    data_df['MDH_{}_std'.format(f)] = data_df.groupby(['month','day','hour'])[f].transform('std')\n",
    "\n",
    "    group_feats.append('MDH_{}_medi'.format(f))\n",
    "    group_feats.append('MDH_{}_mean'.format(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 45.00it/s]\n"
     ]
    }
   ],
   "source": [
    "# 基本交叉特征\n",
    "for f1 in tqdm(['outdoorTemp','outdoorHum','outdoorAtmo','indoorHum','indoorAtmo']+group_feats):\n",
    "    \n",
    "    for f2 in ['outdoorTemp','outdoorHum','outdoorAtmo','indoorHum','indoorAtmo']+group_feats:\n",
    "        if f1 != f2:\n",
    "            colname = '{}_{}_ratio'.format(f1, f2)\n",
    "            data_df[colname] = data_df[f1].values / data_df[f2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df.fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 历史信息提取\n",
    "data_df['dt'] = data_df['day'].values + (data_df['month'].values - 3) * 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:01<00:00, 26.07it/s]\n",
      "100%|██████████| 30/30 [00:01<00:00, 19.59it/s]\n",
      "100%|██████████| 30/30 [00:01<00:00, 24.32it/s]\n",
      "100%|██████████| 30/30 [00:01<00:00, 26.55it/s]\n",
      "100%|██████████| 30/30 [00:01<00:00, 26.93it/s]\n",
      "100%|██████████| 30/30 [00:01<00:00, 27.07it/s]\n"
     ]
    }
   ],
   "source": [
    "for f in ['outdoorTemp','outdoorHum','outdoorAtmo','indoorHum','indoorAtmo', 'temperature']:\n",
    "    tmp_df = pd.DataFrame()\n",
    "    for t in tqdm(range(15, 45)):\n",
    "        tmp = data_df[data_df['dt']<t].groupby(['hour'])[f].agg({'mean'}).reset_index()\n",
    "        tmp.columns = ['hour','hit_{}_mean'.format(f)]\n",
    "        tmp['dt'] = t\n",
    "        tmp_df = tmp_df.append(tmp)\n",
    "    \n",
    "    data_df = data_df.merge(tmp_df, on=['dt','hour'], how='left')\n",
    "    \n",
    "data_df = data_df.fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:11<00:00,  2.22s/it]\n",
      "100%|██████████| 5/5 [00:13<00:00,  2.75s/it]\n",
      "100%|██████████| 5/5 [00:15<00:00,  3.08s/it]\n",
      "100%|██████████| 5/5 [00:19<00:00,  3.88s/it]\n"
     ]
    }
   ],
   "source": [
    "# 离散化\n",
    "for f in ['outdoorTemp','outdoorHum','outdoorAtmo','indoorHum','indoorAtmo']:\n",
    "    data_df[f+'_20_bin'] = pd.cut(data_df[f], 20, duplicates='drop').apply(lambda x:x.left).astype(int)\n",
    "    data_df[f+'_50_bin'] = pd.cut(data_df[f], 50, duplicates='drop').apply(lambda x:x.left).astype(int)\n",
    "    data_df[f+'_100_bin'] = pd.cut(data_df[f], 100, duplicates='drop').apply(lambda x:x.left).astype(int)\n",
    "    data_df[f+'_200_bin'] = pd.cut(data_df[f], 200, duplicates='drop').apply(lambda x:x.left).astype(int)\n",
    "    \n",
    "for f1 in tqdm(['outdoorTemp_20_bin','outdoorHum_20_bin','outdoorAtmo_20_bin','indoorHum_20_bin','indoorAtmo_20_bin']):\n",
    "    for f2 in ['outdoorTemp','outdoorHum','outdoorAtmo','indoorHum','indoorAtmo']:\n",
    "        data_df['{}_{}_medi'.format(f1,f2)] = data_df.groupby([f1])[f2].transform('median')\n",
    "        data_df['{}_{}_mean'.format(f1,f2)] = data_df.groupby([f1])[f2].transform('mean')\n",
    "        data_df['{}_{}_max'.format(f1,f2)] = data_df.groupby([f1])[f2].transform('max')\n",
    "        data_df['{}_{}_min'.format(f1,f2)] = data_df.groupby([f1])[f2].transform('min')\n",
    "       \n",
    "        \n",
    "for f1 in tqdm(['outdoorTemp_50_bin','outdoorHum_50_bin','outdoorAtmo_50_bin','indoorHum_50_bin','indoorAtmo_50_bin']):\n",
    "    for f2 in ['outdoorTemp','outdoorHum','outdoorAtmo','indoorHum','indoorAtmo']:\n",
    "        data_df['{}_{}_medi'.format(f1,f2)] = data_df.groupby([f1])[f2].transform('median')\n",
    "        data_df['{}_{}_mean'.format(f1,f2)] = data_df.groupby([f1])[f2].transform('mean')\n",
    "        data_df['{}_{}_max'.format(f1,f2)] = data_df.groupby([f1])[f2].transform('max')\n",
    "        data_df['{}_{}_min'.format(f1,f2)] = data_df.groupby([f1])[f2].transform('min')\n",
    "        \n",
    "for f1 in tqdm(['outdoorTemp_100_bin','outdoorHum_100_bin','outdoorAtmo_100_bin','indoorHum_100_bin','indoorAtmo_100_bin']):\n",
    "    for f2 in ['outdoorTemp','outdoorHum','outdoorAtmo','indoorHum','indoorAtmo']:\n",
    "        data_df['{}_{}_medi'.format(f1,f2)] = data_df.groupby([f1])[f2].transform('median')\n",
    "        data_df['{}_{}_mean'.format(f1,f2)] = data_df.groupby([f1])[f2].transform('mean')\n",
    "        data_df['{}_{}_max'.format(f1,f2)] = data_df.groupby([f1])[f2].transform('max')\n",
    "        data_df['{}_{}_min'.format(f1,f2)] = data_df.groupby([f1])[f2].transform('min')\n",
    "        \n",
    "for f1 in tqdm(['outdoorTemp_200_bin','outdoorHum_200_bin','outdoorAtmo_200_bin','indoorHum_200_bin','indoorAtmo_200_bin']):\n",
    "    for f2 in ['outdoorTemp','outdoorHum','outdoorAtmo','indoorHum','indoorAtmo']:\n",
    "        data_df['{}_{}_medi'.format(f1,f2)] = data_df.groupby([f1])[f2].transform('median')\n",
    "        data_df['{}_{}_mean'.format(f1,f2)] = data_df.groupby([f1])[f2].transform('mean')\n",
    "        data_df['{}_{}_max'.format(f1,f2)] = data_df.groupby([f1])[f2].transform('max')\n",
    "        data_df['{}_{}_min'.format(f1,f2)] = data_df.groupby([f1])[f2].transform('min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns=[\"time\",\"year\",\"sec\",\"temperature\", 'date']\n",
    "\n",
    "\n",
    "train_count = train_df.shape[0]\n",
    "train_df = data_df[:train_count].copy().reset_index(drop=True)\n",
    "test_df = data_df[train_count:].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train_df[:1].drop(drop_columns,axis=1).columns\n",
    "x_train = train_df[features]\n",
    "x_test = test_df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df['temperature'].values - train_df['outdoorTemp'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.zeros((x_train.shape[0], 1))\n",
    "test = np.zeros((x_test.shape[0], 1))\n",
    "\n",
    "nums = int(x_train.shape[0] * 0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_x, trn_y, val_x, val_y = x_train[:nums], y_train[:nums], x_train[nums:], y_train[nums:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_matrix = xgb.DMatrix(trn_x , label=trn_y, missing=np.nan)\n",
    "valid_matrix = xgb.DMatrix(val_x , label=val_y, missing=np.nan)\n",
    "test_matrix  = xgb.DMatrix(x_test, missing=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:46:52] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-mae:0.64649\teval-mae:0.34919\n",
      "Multiple eval metrics have been passed: 'eval-mae' will be used for early stopping.\n",
      "\n",
      "Will train until eval-mae hasn't improved in 1000 rounds.\n",
      "[500]\ttrain-mae:0.40526\teval-mae:0.24752\n",
      "[1000]\ttrain-mae:0.26004\teval-mae:0.19836\n",
      "[1500]\ttrain-mae:0.17420\teval-mae:0.17689\n",
      "[2000]\ttrain-mae:0.12446\teval-mae:0.16761\n",
      "[2500]\ttrain-mae:0.09627\teval-mae:0.16345\n",
      "[3000]\ttrain-mae:0.08047\teval-mae:0.16183\n",
      "[3500]\ttrain-mae:0.07158\teval-mae:0.16109\n",
      "[4000]\ttrain-mae:0.06636\teval-mae:0.16048\n",
      "[4500]\ttrain-mae:0.06318\teval-mae:0.15999\n",
      "[5000]\ttrain-mae:0.06112\teval-mae:0.15958\n",
      "[5500]\ttrain-mae:0.05969\teval-mae:0.15934\n",
      "[6000]\ttrain-mae:0.05865\teval-mae:0.15909\n",
      "[6500]\ttrain-mae:0.05784\teval-mae:0.15892\n",
      "[7000]\ttrain-mae:0.05711\teval-mae:0.15880\n",
      "[7500]\ttrain-mae:0.05642\teval-mae:0.15867\n",
      "[8000]\ttrain-mae:0.05575\teval-mae:0.15865\n",
      "[8500]\ttrain-mae:0.05513\teval-mae:0.15863\n",
      "[9000]\ttrain-mae:0.05452\teval-mae:0.15865\n",
      "[9500]\ttrain-mae:0.05393\teval-mae:0.15862\n",
      "[10000]\ttrain-mae:0.05333\teval-mae:0.15864\n",
      "Stopping. Best iteration:\n",
      "[9408]\ttrain-mae:0.05403\teval-mae:0.15861\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {'booster': 'gbtree',\n",
    "          'eval_metric': 'mae',\n",
    "          'min_child_weight': 5,\n",
    "          'max_depth': 8,\n",
    "          'subsample': 0.5,\n",
    "          'colsample_bytree': 0.5,\n",
    "          'eta': 0.001,\n",
    "          'seed': 2020,\n",
    "          'nthread': 36,\n",
    "          'silent': True,\n",
    "          }\n",
    "\n",
    "watchlist = [(train_matrix, 'train'),(valid_matrix, 'eval')]\n",
    "\n",
    "model = xgb.train(params, train_matrix, num_boost_round=50000, evals=watchlist, verbose_eval=500, early_stopping_rounds=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred  = model.predict(valid_matrix, ntree_limit=model.best_ntree_limit).reshape(-1,1)\n",
    "test_pred = model.predict(test_matrix , ntree_limit=model.best_ntree_limit).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub[\"temperature\"] = test_pred + test_df['outdoorTemp'].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
